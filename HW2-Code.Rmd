---
title: "HW2-R"
author: "Nima Kelidari"
date: "2023-05-02"
output:
  html_document: default
  pdf_document: default
---

I decided to use the second dataset which data is 50-50 for diabetic and non-diabetic persons. this balance will help us to decrease bias in our models. And it is cleaner and has less same row and NA rows so much. (But we try to detect and delete them anyway)


```{r}

#install.packages('caret')
#install.packages('pROC')
#install.packages("ggplot2")
#install.packages("tidyverse")
#install.packages("leaps")
#install.packages("MASS")
#install.packages("tree")
library("tree")
library(tidyverse)
library(leaps)
library(MASS)
library(ggplot2)
library(pROC)
library(caret)
diabets = read.csv("D:/Terme8/Regression/HW2/Data/d2.csv")

```

```{r}
#diabets
```

```{r}
diabets <- diabets[!duplicated(diabets), ]
diabets <- na.omit(diabets)
diabets$output <- as.factor(diabets$Diabetes_binary)

#diabets
```
 
 
 
 
 
 
  

[**PART 1**]{.underline}

Yes, by using the proper features and model, we surely can get a nice prediction and then in the next part, use it for inference. The main reason for this is the data given to us, has some features which probably have some relationship with the probability of whether one has diabetes or not. We can show it by plotting those features by the diabetes factor. For example, we plotted BMI, high blood pressure, high cholesterol, general health, age, education, and income by diabetes factor in the type of histogram density, histogram, and box plot. Here we can see the different distribution of these factors for two groups of diabetic and non-diabetic persons. Moreover, we fit a logistic regression to show t-value is so big for this problem and that these factors and responses are correlated strongly. At last, we fit a model by these factors and see almost all of them, have strongly related to the diabetes factor. So as least some of them can be used for the prediction of whether one has diabetes or not. In the second part, we introduce some of these features as good ones for prediction.

```{r}
model <- glm(Diabetes_binary ~ BMI, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = BMI, fill = Diabetstic , colours = Diabetstic)) +
  geom_density(alpha = 0.4, color = NA) 
```

```{r}
model <- glm(Diabetes_binary ~ HighBP, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = HighBP, fill = Diabetstic , colours = Diabetstic)) +
  geom_histogram(alpha = 0.4, position = "identity",bins = 3) 
```

(legend.position = "none")
```{r}
model <- glm(Diabetes_binary ~ HighChol, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = HighChol, fill = Diabetstic , colours = Diabetstic)) +
  geom_histogram(alpha = 0.4, position = "identity",bins = 3) 
```

```{r}
model <- glm(Diabetes_binary ~ GenHlth, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = GenHlth, fill = Diabetstic , colours = Diabetstic)) +
  geom_histogram(alpha = 1, position = "dodge",bins = 9) 
```

```{r}
model <- glm(Diabetes_binary ~ Age, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = Age, fill = Diabetstic , colours = Diabetstic)) +
  geom_boxplot(alpha = 1) 
```

```{r}
model <- glm(Diabetes_binary ~ Education, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = Education, fill = Diabetstic , colours = Diabetstic)) +
  geom_histogram(alpha = 0.4, position = "identity",bins = 8) 
```

```{r}
model <- glm(Diabetes_binary ~ Income, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
# Density areas without lines
ggplot(diabets, aes(x = Income, fill = Diabetstic , colours = Diabetstic)) +
  geom_histogram(alpha = 1, position = "dodge",bins = 6) 
```

```{r}
model <- glm(Diabetes_binary ~ Income+Education+Age+GenHlth+HighChol+HighBP+BMI, data = diabets)
summary(model)
Diabetstic = as.factor(diabets$Diabetes_binary)
```
 
 
 
 
 
 
 
  
 
 
[**PART 2**]{.underline}

We can answer this question by feat a model like logistic regression on whole data and all of the features, then detect those features which have big enough t-values. Here we can see BMI, high blood pressure, high cholesterol, general health, age, cholesterol check, history of heart attack, sex, age, heavy alcohol consumption, and income have an absolute value of t-value more than 10; We can detect these factors as important factors compared to others and check them more carefully. we will see how we can select features more reliably by feature selection in part 3.

```{r}
md  <- glm(Diabetes_binary ~., data = diabets)
summary(md)
```
 
  
  
  
   
   
  
  
  
  
  
[**PART 3**]{.underline}

Yes, absolutely we can do it by feature selection methods. As best subset selection can be very time-consuming and computationally heavy in practice ( in real cases), we just use two methods forward and backward selection by AIC. In each one, we want to use 5 features maximum utmost. so we make a full model and null model first and try to extract the five most important features. By each of these two methods, we can see five features below BMI, high blood pressure, high cholesterol, general health, and age, have the most importance in prediction as we guss before in part 2; in other words, these have most dependency to pred factor. On another hand, these do have not a significant relation to each other, because, in a model that we created before, they didn't decrease each other t-value strongly. so we use these five features for use in the next parts.


```{r}

full.model <- glm(Diabetes_binary ~.-output, data = diabets)
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
summary(step.model)

train.control <- trainControl(method = "cv", number = 10)
step.model <- train(Diabetes_binary ~.-output, data = diabets,
                    method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:5),
                    trControl = train.control
                    )
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
mod <- glm(Diabetes_binary ~ HighBP + HighChol + BMI + GenHlth + Age, 
   data = diabets)
summary(mod)
```


```{r}

full.model <- glm(Diabetes_binary ~.-output, data = diabets)
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
summary(step.model)

set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
step.model <- train(Diabetes_binary ~.-output, data = diabets,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:5),
                    trControl = train.control
                    )
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, 5)
mod <- glm(Diabetes_binary ~ HighBP + HighChol + BMI + GenHlth + Age, 
   data = diabets)
summary(mod)
```
 
 
 
 
 
 
 
 
[**PART 4**]{.underline}

We will use the five features that are mentioned in the last part. If we use all of the features or more than five, our efficiency for the trained model will drop. in this part, we use 70 percent of the data for the training and 30 of the data for the test. here we will not use a validation set and we prefer to use cross-validation, more specifically 5fold-cv for it,s time-consuming. then we will try to train the model, tune its hyperparameters, and then test it and get accuracy and precision, and recall from them, then make the confusion matrix for each model based on the test set. We here will use QDA, LDA, Randomforrest,  Neural Network, Tree, Linear SVM, Logistic regression, and KNN models. after the test, we will save the accuracy of each model and show and compare them at last and choose one of them. (Here we can see the Tree model had excellent performance besides its simplicity)

```{r}
diabets$Diabetes_binary <- as.factor(diabets$Diabetes_binary)
preProcess <- c("center","scale")
i <- createDataPartition(y = diabets$Diabetes_binary, times = 1, p = 0.7, list = FALSE)
training_set <- diabets[i,]
test_set <- diabets[-i,]
trControl <- trainControl(method = "cv",number = 5)
```


```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='qda', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_qda <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```


```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='rf', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_rf <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```
1


```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='lda', data = training_set, metric='Accuracy',preProcess = preProcess,trainControl = trainControl(method = "cv"))
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_lda <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```
```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='nnet', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_nn <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```

```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='ctree', data = training_set)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_tree <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```

```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='svmLinear', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_svm <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```


```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='LogitBoost', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_lr <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```

```{r}
model <- train(Diabetes_binary ~ Age+GenHlth+HighChol+HighBP+BMI, method='knn', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)
summary(model)
test_set$pred <- predict(model, test_set)
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Diabetes_binary)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table
test_set$pred <- predict(model, test_set,probability=TRUE)
#________________________________________________
print(paste("Precision: ",precision))
print(paste("Accuracy: ",accuracy))
print(paste("Recall: ",recall))
acc_knn <- accuracy
#________________________________________________
Reference <- factor(c(0, 1, 0, 1))
Prediction   <- factor(c(0, 0, 1, 1))
Y  <- array(cmat)
df <- data.frame(Prediction, Reference, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") 
```






```{r}
print(paste('Accuracy in QDA:',acc_qda*100,'%'))
print(paste('Accuracy in LDA:',acc_lda*100,'%'))
print(paste('Accuracy in Randomforrest:',acc_rf*100,'%'))
print(paste('Accuracy in Neural Network:',acc_nn*100,'%'))
print(paste('Accuracy in CTree:',acc_tree*100,'%'))
print(paste('Accuracy in Linear SVM:',acc_svm*100,'%'))
print(paste('Accuracy in Logreg:',acc_lr*100,'%'))
print(paste('Accuracy in knn:',acc_knn*100,'%'))

```


[**PART 5**]{.underline}

Yes, we can do this thing. For this target, we need to use a simple and appropriate inferentially. As we want to ask some questions as less as possible from a person, I prefer to use the Tree model. In the last part, we understood Tree can do nice predictions too. so use a big tree and use cross-validation to get how many nodes and terminals we need for a good model. So we choose 8 and get accuracy, a plot of the Tree, and a confusion matrix for this model. By this tree, we can by asking just some questions, we can predict whether one has diabetes or not, with acceptable accuracy.

```{r}

tree_model <- tree(Diabetes_binary ~ .-output , training_set , mindev=7e-4, minsize=8)
summary(tree_model)
plot(tree_model)
text(tree_model, pretty = 0)

test_set$pred <- predict(tree_model, test_set,type="class")
ErrorPrune<-mean(test_set$pred!=test_set$Diabetes_binary)
cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table

real <- factor(c(0, 0, 1, 1))
pred   <- factor(c(0, 1, 0, 1))
Y  <- array(cmat)
df <- data.frame(pred, real, Y)

ggplot(data =  df, mapping = aes(x = real, y = pred)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") +
  theme_bw()

print(paste('Error rate :',ErrorPrune))
```

```{r}
cv.tree<-cv.tree(tree_model, FUN=prune.tree)
cv.tree
plot(cv.tree)
```

```{r}
prune.tree<-prune.misclass(tree_model,best = 8)
plot(prune.tree);text(prune.tree)


test_set$pred <- predict(prune.tree, test_set,type="class")
ErrorPrune<-mean(test_set$pred!=test_set$Diabetes_binary)

cm <- confusionMatrix(test_set$pred, test_set$Diabetes_binary)
accuracy <- cm$overall[1]
cmat <- cm$table

real <- factor(c(0, 0, 1, 1))
pred   <- factor(c(0, 1, 0, 1))
Y  <- array(cmat)
df <- data.frame(pred, real, Y)

library(ggplot2)
ggplot(data =  df, mapping = aes(x = real, y = pred)) +
  geom_tile(aes(fill = Y), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
  scale_fill_gradient(low = "#ffffcc", high = "yellow") +
  theme_bw()

print(paste('New Error rate :',ErrorPrune))


print(paste('New accuracy :',((1-ErrorPrune)*100),'%'))
```

